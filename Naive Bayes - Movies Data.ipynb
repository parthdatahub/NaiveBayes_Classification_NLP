{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca6ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Algorithm\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a51d7d5",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed400ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_folder_path = r\"movie_reviews\\pos\"\n",
    "neg_folder_path = r\"movie_reviews\\neg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b6f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review_files = glob.glob(f\"{pos_folder_path}\\\\*.txt\")\n",
    "neg_review_files = glob.glob(f\"{neg_folder_path}\\\\*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f868958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def lemmitization(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    post = PorterStemmer()\n",
    "    \n",
    "    output_text = []\n",
    "    for word in tokens:\n",
    "        lem_word = post.stem(word.lower())\n",
    "        output_text.append(lem_word)\n",
    "    \n",
    "    text = \" \".join(output_text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab0546f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python is program languag and python languag is prefer for data scienc'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Python is Programming Language and Python Language is Preferable for Data Science\"\n",
    "\n",
    "lemmitization(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ae10af3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_list = []\n",
    "\n",
    "for file_name in pos_review_files:\n",
    "#     print(\"*\" * 50 ,\"File Name -->\", file_name)\n",
    "    with open(file_name, \"r\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "    # Normalize the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub('[^a-z]', \" \", text)\n",
    "    \n",
    "    # function call\n",
    "    text = lemmitization(text)\n",
    "    \n",
    "    review_list.append(text)\n",
    "    \n",
    "for file_name in neg_review_files:\n",
    "#     print(\"*\" * 50 ,\"File Name -->\", file_name)\n",
    "    with open(file_name, \"r\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "    # Normalize the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Clean the text\n",
    "    text = re.sub('[^a-z]', \" \", text)\n",
    "    \n",
    "    # function call\n",
    "    text = lemmitization(text)\n",
    "    \n",
    "    review_list.append(text)\n",
    "    \n",
    "len(review_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bcd310b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "1995    0\n",
       "1996    0\n",
       "1997    0\n",
       "1998    0\n",
       "1999    0\n",
       "Length: 2000, dtype: int32"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Target Column\n",
    "pos_target = np.ones(len(pos_review_files), dtype=int)\n",
    "neg_target = np.zeros(len(neg_review_files), dtype=int)\n",
    "\n",
    "y = np.append(pos_target, neg_target)\n",
    "\n",
    "y = pd.Series(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad1afc",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "329949b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abov</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accent</th>\n",
       "      <th>accept</th>\n",
       "      <th>achiev</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>wouldn</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1017 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abil  abl  abov  absolut  accent  accept  achiev  act  action  actor  \\\n",
       "0        0    0     0        0       2       0       0    2       0      0   \n",
       "1        0    0     0        0       0       0       1    0       0      0   \n",
       "2        0    0     0        1       0       0       0    1       0      0   \n",
       "3        0    0     0        0       0       0       0    6       0      1   \n",
       "4        0    0     0        0       0       0       0    6       0      1   \n",
       "...    ...  ...   ...      ...     ...     ...     ...  ...     ...    ...   \n",
       "1995     0    0     0        1       0       0       0    0       0      0   \n",
       "1996     1    0     0        0       0       0       0    0       0      0   \n",
       "1997     1    0     0        0       0       0       0    1       0      1   \n",
       "1998     0    0     0        0       0       0       0    0       0      1   \n",
       "1999     0    0     0        0       0       0       0    0       0      0   \n",
       "\n",
       "      ...  wouldn  write  writer  written  wrong  wrote  ye  year  york  young  \n",
       "0     ...       0      0       0        0      0      0   0     0     0      0  \n",
       "1     ...       0      0       0        0      0      0   0     1     0      0  \n",
       "2     ...       0      0       0        0      0      0   0     2     0      0  \n",
       "3     ...       0      0       0        0      0      0   0     1     1      1  \n",
       "4     ...       0      0       0        0      0      0   0     1     1      1  \n",
       "...   ...     ...    ...     ...      ...    ...    ...  ..   ...   ...    ...  \n",
       "1995  ...       1      0       0        0      0      0   1     2     0      0  \n",
       "1996  ...       1      0       0        0      0      0   0     2     0      0  \n",
       "1997  ...       0      0       0        0      0      0   0     0     0      0  \n",
       "1998  ...       1      0       0        1      1      0   0     0     0      0  \n",
       "1999  ...       0      0       0        0      0      0   0     0     0      0  \n",
       "\n",
       "[2000 rows x 1017 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Instance\n",
    "cnt_vector = CountVectorizer(stop_words='english', min_df = 0.05)\n",
    "\n",
    "x_cnt_array = cnt_vector.fit_transform(review_list).toarray()\n",
    "\n",
    "x_cnt = pd.DataFrame(x_cnt_array, columns=cnt_vector.get_feature_names())\n",
    "x_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abc60b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnt_vector.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be24ebe",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c631f640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abov</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accent</th>\n",
       "      <th>accept</th>\n",
       "      <th>achiev</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>wouldn</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 1017 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abil  abl  abov  absolut  accent  accept  achiev  act  action  actor  \\\n",
       "118      0    0     0        0       0       0       0    0       0      2   \n",
       "1374     0    0     0        0       0       0       0    2       1      0   \n",
       "1928     0    0     0        0       0       0       0    2       1      1   \n",
       "250      0    1     0        0       0       4       0    1       0      0   \n",
       "1621     0    0     0        0       0       0       0    3       0      0   \n",
       "...    ...  ...   ...      ...     ...     ...     ...  ...     ...    ...   \n",
       "1459     0    1     0        0       0       0       0    1       0      2   \n",
       "1730     0    0     0        0       0       0       0    2       0      1   \n",
       "725      0    0     0        0       0       1       0    0       1      0   \n",
       "850      0    0     0        0       0       0       0    1       0      0   \n",
       "1706     0    0     0        0       0       0       1    4       0      0   \n",
       "\n",
       "      ...  wouldn  write  writer  written  wrong  wrote  ye  year  york  young  \n",
       "118   ...       0      0       0        0      0      0   0     0     0      0  \n",
       "1374  ...       0      0       0        0      0      0   0     0     0      0  \n",
       "1928  ...       1      0       0        0      0      0   0     1     0      0  \n",
       "250   ...       0      0       0        1      0      0   0     1     0      0  \n",
       "1621  ...       2      0       0        0      0      0   0     1     0      3  \n",
       "...   ...     ...    ...     ...      ...    ...    ...  ..   ...   ...    ...  \n",
       "1459  ...       0      0       0        0      0      0   0     0     0      0  \n",
       "1730  ...       0      0       0        0      0      0   0     0     0      1  \n",
       "725   ...       0      0       0        0      1      0   0     2     2      0  \n",
       "850   ...       0      0       0        0      0      0   0     0     0      0  \n",
       "1706  ...       0      2       0        1      1      0   1     1     0      0  \n",
       "\n",
       "[1500 rows x 1017 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_cnt, y, test_size=0.25, random_state=25, stratify=y)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef24614",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72c1c4",
   "metadata": {},
   "source": [
    "### 1. GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fa20f8",
   "metadata": {},
   "source": [
    "For good reults, data is continous and should be normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "679223c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "485edaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[209 108]\n",
      " [ 41 142]]\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.702\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.66      0.74       317\n",
      "           1       0.57      0.78      0.66       183\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.70      0.72      0.70       500\n",
      "weighted avg       0.74      0.70      0.71       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Model Evaluation\n",
    "\n",
    "y_pred = gnb_model.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "print(\"-\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"-\"*60)\n",
    "\n",
    "clf_report = classification_report(y_pred, y_test)\n",
    "print(\"Classification Report:\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "499f3ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[678 221]\n",
      " [ 72 529]]\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.8046666666666666\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82       899\n",
      "           1       0.71      0.88      0.78       601\n",
      "\n",
      "    accuracy                           0.80      1500\n",
      "   macro avg       0.80      0.82      0.80      1500\n",
      "weighted avg       0.82      0.80      0.81      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Model Evaluation\n",
    "\n",
    "y_pred_train = gnb_model.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "print(\"-\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_pred_train, y_train)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"-\"*60)\n",
    "\n",
    "clf_report = classification_report(y_pred_train, y_train)\n",
    "print(\"Classification Report:\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f84f22",
   "metadata": {},
   "source": [
    "## 2. Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954815fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Will perform well on descrete data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d110decd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a60a3c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[203  55]\n",
      " [ 47 195]]\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.796\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       258\n",
      "           1       0.78      0.81      0.79       242\n",
      "\n",
      "    accuracy                           0.80       500\n",
      "   macro avg       0.80      0.80      0.80       500\n",
      "weighted avg       0.80      0.80      0.80       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Model Evaluation\n",
    "\n",
    "y_pred = mnb_model.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "print(\"-\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"-\"*60)\n",
    "\n",
    "clf_report = classification_report(y_pred, y_test)\n",
    "print(\"Classification Report:\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e21a7573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[630 124]\n",
      " [120 626]]\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.8373333333333334\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       754\n",
      "           1       0.83      0.84      0.84       746\n",
      "\n",
      "    accuracy                           0.84      1500\n",
      "   macro avg       0.84      0.84      0.84      1500\n",
      "weighted avg       0.84      0.84      0.84      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Model Evaluation\n",
    "\n",
    "y_pred_train = mnb_model.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "print(\"-\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_pred_train, y_train)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"-\"*60)\n",
    "\n",
    "clf_report = classification_report(y_pred_train, y_train)\n",
    "print(\"Classification Report:\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba9703a",
   "metadata": {},
   "source": [
    "## 3. Bernoullis NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0665311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "When we have binary descrete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b243cc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_model = BernoulliNB()\n",
    "bnb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "38b2de84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[201  72]\n",
      " [ 49 178]]\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.758\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       273\n",
      "           1       0.71      0.78      0.75       227\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.76      0.76      0.76       500\n",
      "weighted avg       0.76      0.76      0.76       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Model Evaluation\n",
    "\n",
    "y_pred = bnb_model.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "print(\"-\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"-\"*60)\n",
    "\n",
    "clf_report = classification_report(y_pred, y_test)\n",
    "print(\"Classification Report:\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "920b238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[659 166]\n",
      " [ 91 584]]\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.8286666666666667\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84       825\n",
      "           1       0.78      0.87      0.82       675\n",
      "\n",
      "    accuracy                           0.83      1500\n",
      "   macro avg       0.83      0.83      0.83      1500\n",
      "weighted avg       0.83      0.83      0.83      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Model Evaluation\n",
    "\n",
    "y_pred_train = bnb_model.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "print(\"-\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_pred_train, y_train)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"-\"*60)\n",
    "\n",
    "clf_report = classification_report(y_pred_train, y_train)\n",
    "print(\"Classification Report:\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256622f",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4f40c909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abov</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accent</th>\n",
       "      <th>accept</th>\n",
       "      <th>achiev</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>wouldn</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027060</td>\n",
       "      <td>0.055536</td>\n",
       "      <td>0.037962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027060</td>\n",
       "      <td>0.055536</td>\n",
       "      <td>0.037962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039886</td>\n",
       "      <td>0.041935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.057076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.088080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063397</td>\n",
       "      <td>0.064761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1017 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          abil  abl  abov   absolut    accent  accept    achiev       act  \\\n",
       "0     0.000000  0.0   0.0  0.000000  0.154051     0.0  0.000000  0.077617   \n",
       "1     0.000000  0.0   0.0  0.000000  0.000000     0.0  0.063681  0.000000   \n",
       "2     0.000000  0.0   0.0  0.089848  0.000000     0.0  0.000000  0.053714   \n",
       "3     0.000000  0.0   0.0  0.000000  0.000000     0.0  0.000000  0.189863   \n",
       "4     0.000000  0.0   0.0  0.000000  0.000000     0.0  0.000000  0.189863   \n",
       "...        ...  ...   ...       ...       ...     ...       ...       ...   \n",
       "1995  0.000000  0.0   0.0  0.041013  0.000000     0.0  0.000000  0.000000   \n",
       "1996  0.057076  0.0   0.0  0.000000  0.000000     0.0  0.000000  0.000000   \n",
       "1997  0.088080  0.0   0.0  0.000000  0.000000     0.0  0.000000  0.049845   \n",
       "1998  0.000000  0.0   0.0  0.000000  0.000000     0.0  0.000000  0.000000   \n",
       "1999  0.000000  0.0   0.0  0.000000  0.000000     0.0  0.000000  0.000000   \n",
       "\n",
       "      action     actor  ...    wouldn  write  writer   written     wrong  \\\n",
       "0        0.0  0.000000  ...  0.000000    0.0     0.0  0.000000  0.000000   \n",
       "1        0.0  0.000000  ...  0.000000    0.0     0.0  0.000000  0.000000   \n",
       "2        0.0  0.000000  ...  0.000000    0.0     0.0  0.000000  0.000000   \n",
       "3        0.0  0.030716  ...  0.000000    0.0     0.0  0.000000  0.000000   \n",
       "4        0.0  0.030716  ...  0.000000    0.0     0.0  0.000000  0.000000   \n",
       "...      ...       ...  ...       ...    ...     ...       ...       ...   \n",
       "1995     0.0  0.000000  ...  0.042116    0.0     0.0  0.000000  0.000000   \n",
       "1996     0.0  0.000000  ...  0.055481    0.0     0.0  0.000000  0.000000   \n",
       "1997     0.0  0.048384  ...  0.000000    0.0     0.0  0.000000  0.000000   \n",
       "1998     0.0  0.044201  ...  0.078218    0.0     0.0  0.063397  0.064761   \n",
       "1999     0.0  0.000000  ...  0.000000    0.0     0.0  0.000000  0.000000   \n",
       "\n",
       "      wrote        ye      year      york     young  \n",
       "0       0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "1       0.0  0.000000  0.029383  0.000000  0.000000  \n",
       "2       0.0  0.000000  0.091867  0.000000  0.000000  \n",
       "3       0.0  0.000000  0.027060  0.055536  0.037962  \n",
       "4       0.0  0.000000  0.027060  0.055536  0.037962  \n",
       "...     ...       ...       ...       ...       ...  \n",
       "1995    0.0  0.039886  0.041935  0.000000  0.000000  \n",
       "1996    0.0  0.000000  0.055242  0.000000  0.000000  \n",
       "1997    0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "1998    0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "1999    0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[2000 rows x 1017 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Instance\n",
    "tfidf_vector = TfidfVectorizer(stop_words='english', min_df = 0.05)\n",
    "\n",
    "x_tfidf_array = tfidf_vector.fit_transform(review_list).toarray()\n",
    "\n",
    "x_tfidf = pd.DataFrame(x_tfidf_array, columns=tfidf_vector.get_feature_names())\n",
    "x_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cf964d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abil', 'abl', 'abov', 'absolut', 'accent', 'accept', 'achiev', 'act', 'action', 'actor', 'actress', 'actual', 'ad', 'adapt', 'add', 'addit', 'admir', 'admit', 'adult', 'adventur', 'affect', 'age', 'agent', 'ago', 'agre', 'air', 'alien', 'aliv', 'allow', 'alon', 'alreadi', 'alway', 'amaz', 'america', 'american', 'amus', 'ani', 'anim', 'annoy', 'anoth', 'answer', 'anyon', 'anyth', 'apart', 'appar', 'appeal', 'appear', 'appreci', 'approach', 'appropri', 'aren', 'arm', 'arriv', 'art', 'artist', 'asid', 'ask', 'aspect', 'assist', 'atmospher', 'attack', 'attempt', 'attent', 'attract', 'audienc', 'author', 'averag', 'avoid', 'aw', 'award', 'away', 'babi', 'background', 'bad', 'bare', 'base', 'basic', 'battl', 'beat', 'beauti', 'becaus', 'becom', 'befor', 'begin', 'believ', 'ben', 'best', 'better', 'big', 'biggest', 'bit', 'black', 'blood', 'blow', 'blue', 'bodi', 'book', 'bore', 'boss', 'box', 'boy', 'brain', 'break', 'brief', 'brilliant', 'bring', 'british', 'brother', 'brought', 'bruce', 'buddi', 'budget', 'build', 'bunch', 'busi', 'buy', 'came', 'cameo', 'camera', 'captur', 'car', 'care', 'career', 'carri', 'case', 'cast', 'catch', 'caught', 'caus', 'center', 'central', 'centuri', 'certain', 'certainli', 'challeng', 'chanc', 'chang', 'charact', 'charm', 'chase', 'cheap', 'chemistri', 'child', 'children', 'choic', 'chri', 'cinema', 'cinemat', 'cinematographi', 'citi', 'claim', 'class', 'classic', 'clear', 'clearli', 'clever', 'clich', 'climax', 'close', 'club', 'cold', 'collect', 'colleg', 'color', 'combin', 'come', 'comedi', 'comic', 'command', 'commit', 'common', 'commun', 'compani', 'compar', 'complet', 'complex', 'comput', 'concept', 'concern', 'conclus', 'conflict', 'confront', 'confus', 'connect', 'consid', 'consist', 'constantli', 'contain', 'continu', 'control', 'convinc', 'cool', 'cop', 'costum', 'couldn', 'count', 'countri', 'coupl', 'cours', 'cover', 'crash', 'creat', 'creatur', 'credit', 'crew', 'crime', 'critic', 'cross', 'cultur', 'current', 'cut', 'cute', 'damn', 'danc', 'danger', 'dark', 'date', 'daughter', 'david', 'day', 'dead', 'deal', 'death', 'debut', 'decad', 'decent', 'decid', 'decis', 'deep', 'definit', 'delight', 'deliv', 'depress', 'depth', 'describ', 'deserv', 'design', 'desir', 'desper', 'despit', 'destroy', 'detect', 'determin', 'develop', 'devic', 'dialogu', 'did', 'didn', 'die', 'differ', 'difficult', 'direct', 'director', 'disappoint', 'discov', 'display', 'distract', 'disturb', 'doctor', 'doe', 'doesn', 'dog', 'dollar', 'don', 'door', 'doubl', 'doubt', 'dr', 'drag', 'drama', 'dramat', 'draw', 'dream', 'dress', 'drive', 'drop', 'drug', 'dull', 'dumb', 'dure', 'earli', 'earlier', 'earth', 'easi', 'easili', 'eat', 'edg', 'edit', 'effect', 'effort', 'element', 'els', 'emot', 'encount', 'end', 'energi', 'engag', 'english', 'enjoy', 'enter', 'entertain', 'entir', 'episod', 'equal', 'escap', 'especi', 'event', 'eventu', 'everi', 'everyon', 'everyth', 'evil', 'ex', 'exactli', 'exampl', 'excel', 'excit', 'execut', 'exist', 'expect', 'experi', 'explain', 'explor', 'express', 'extrem', 'eye', 'face', 'fact', 'fail', 'fair', 'fairli', 'fall', 'famili', 'familiar', 'famou', 'fan', 'fantasi', 'far', 'fascin', 'fashion', 'fast', 'father', 'favorit', 'fear', 'featur', 'feel', 'fellow', 'felt', 'femal', 'fiction', 'fight', 'figur', 'film', 'filmmak', 'final', 'fine', 'fit', 'flat', 'flaw', 'fli', 'flick', 'focu', 'follow', 'forc', 'forget', 'form', 'formula', 'frame', 'free', 'friend', 'frighten', 'fun', 'funni', 'futur', 'gag', 'game', 'gave', 'gener', 'genr', 'genuin', 'georg', 'giant', 'girl', 'girlfriend', 'given', 'god', 'goe', 'gone', 'good', 'got', 'govern', 'grace', 'grant', 'great', 'greatest', 'ground', 'group', 'grow', 'guess', 'gun', 'guy', 'ha', 'hair', 'half', 'hand', 'handl', 'hang', 'happen', 'happi', 'hard', 'hardli', 'harri', 'hate', 'haven', 'head', 'hear', 'heard', 'heart', 'heavi', 'hell', 'help', 'hero', 'hi', 'high', 'highli', 'hilari', 'hire', 'histori', 'hit', 'hold', 'hollywood', 'home', 'hope', 'horribl', 'horror', 'hot', 'hour', 'hous', 'howev', 'huge', 'human', 'humor', 'husband', 'idea', 'imag', 'imagin', 'immedi', 'import', 'imposs', 'impress', 'includ', 'incred', 'inde', 'individu', 'inform', 'initi', 'innoc', 'insid', 'inspir', 'instead', 'intellig', 'intend', 'intens', 'intent', 'intrigu', 'introduc', 'investig', 'involv', 'iron', 'isn', 'issu', 'jack', 'jame', 'jim', 'job', 'joe', 'john', 'join', 'joke', 'jone', 'jump', 'just', 'kevin', 'key', 'kick', 'kid', 'kill', 'killer', 'kind', 'king', 'knew', 'know', 'known', 'la', 'lack', 'ladi', 'lame', 'land', 'languag', 'larg', 'late', 'later', 'latest', 'laugh', 'law', 'lead', 'leader', 'learn', 'leav', 'led', 'lee', 'left', 'length', 'let', 'level', 'lie', 'life', 'light', 'like', 'limit', 'line', 'list', 'liter', 'littl', 'live', 'll', 'local', 'long', 'longer', 'look', 'lose', 'lost', 'lot', 'loud', 'love', 'lover', 'low', 'machin', 'magic', 'main', 'major', 'make', 'male', 'man', 'manag', 'mani', 'manner', 'mark', 'marri', 'martin', 'master', 'match', 'materi', 'matter', 'mayb', 'mean', 'meanwhil', 'meet', 'member', 'memor', 'memori', 'men', 'mention', 'mere', 'mess', 'messag', 'michael', 'middl', 'million', 'mind', 'minor', 'minut', 'miss', 'mission', 'mix', 'modern', 'moment', 'money', 'month', 'moral', 'mostli', 'mother', 'motion', 'motiv', 'mouth', 'movi', 'mr', 'murder', 'music', 'mysteri', 'natur', 'near', 'nearli', 'need', 'new', 'nice', 'night', 'non', 'normal', 'note', 'noth', 'notic', 'novel', 'number', 'obsess', 'obviou', 'obvious', 'occasion', 'occur', 'odd', 'offer', 'offic', 'oh', 'okay', 'old', 'onc', 'onli', 'open', 'oper', 'opinion', 'opportun', 'order', 'origin', 'oscar', 'otherwis', 'outsid', 'overal', 'pace', 'pain', 'pair', 'parent', 'park', 'parti', 'particular', 'particularli', 'partner', 'pass', 'past', 'paul', 'pay', 'peopl', 'perfect', 'perfectli', 'perform', 'perhap', 'period', 'person', 'peter', 'physic', 'pick', 'pictur', 'piec', 'place', 'plan', 'planet', 'play', 'player', 'pleas', 'pleasur', 'plenti', 'plot', 'point', 'polic', 'polit', 'poor', 'pop', 'popular', 'portray', 'posit', 'possess', 'possibl', 'potenti', 'power', 'predict', 'premis', 'presenc', 'present', 'pretti', 'previou', 'prison', 'privat', 'probabl', 'problem', 'produc', 'product', 'project', 'promis', 'protagonist', 'prove', 'provid', 'public', 'pull', 'pure', 'purpos', 'qualiti', 'question', 'quick', 'quickli', 'quit', 'race', 'rais', 'rare', 'rate', 'reach', 'read', 'readi', 'real', 'realist', 'realiti', 'realiz', 'realli', 'reason', 'receiv', 'recent', 'recommend', 'red', 'refer', 'refus', 'rel', 'relat', 'relationship', 'releas', 'remain', 'remark', 'rememb', 'remind', 'replac', 'requir', 'rescu', 'respect', 'respons', 'rest', 'result', 'return', 'reveal', 'review', 'rich', 'richard', 'ride', 'ridicul', 'right', 'rise', 'road', 'robert', 'robin', 'rock', 'role', 'roll', 'romanc', 'romant', 'room', 'root', 'rule', 'run', 'sad', 'said', 'satisfi', 'save', 'saw', 'say', 'scare', 'scari', 'scene', 'school', 'scienc', 'score', 'scott', 'scream', 'screen', 'screenplay', 'screenwrit', 'script', 'search', 'second', 'secret', 'seemingli', 'seen', 'self', 'sell', 'send', 'sens', 'sent', 'sequel', 'sequenc', 'seri', 'seriou', 'serv', 'set', 'sever', 'sex', 'sexual', 'share', 'shine', 'ship', 'shock', 'shoot', 'short', 'shot', 'shown', 'sight', 'sign', 'silli', 'similar', 'simpl', 'simpli', 'sinc', 'sing', 'singl', 'sister', 'sit', 'situat', 'skill', 'slightli', 'slow', 'slowli', 'small', 'smart', 'societi', 'solid', 'someon', 'someth', 'sometim', 'somewhat', 'somewher', 'son', 'song', 'soon', 'sort', 'soul', 'sound', 'soundtrack', 'space', 'speak', 'special', 'spend', 'spent', 'spirit', 'spot', 'stage', 'stand', 'standard', 'star', 'start', 'state', 'stay', 'steal', 'step', 'stereotyp', 'steve', 'steven', 'stick', 'stop', 'store', 'stori', 'straight', 'strang', 'street', 'strike', 'strong', 'struggl', 'student', 'studi', 'studio', 'stuff', 'stupid', 'style', 'subject', 'subplot', 'subtl', 'success', 'suddenli', 'suffer', 'suggest', 'suit', 'summer', 'superior', 'support', 'suppos', 'sure', 'surpris', 'surprisingli', 'surround', 'surviv', 'suspect', 'suspens', 'sweet', 'taken', 'tale', 'talent', 'talk', 'target', 'task', 'team', 'technic', 'teen', 'teenag', 'televis', 'tell', 'tension', 'term', 'terribl', 'terrif', 'th', 'thank', 'theater', 'theme', 'themselv', 'thi', 'thing', 'think', 'thought', 'threaten', 'thrill', 'thriller', 'throw', 'thrown', 'thu', 'time', 'titl', 'today', 'togeth', 'told', 'tom', 'tone', 'took', 'total', 'touch', 'tough', 'town', 'track', 'tradit', 'trailer', 'train', 'travel', 'treat', 'tri', 'trip', 'troubl', 'true', 'truli', 'truth', 'turn', 'tv', 'twenti', 'twist', 'type', 'typic', 'ultim', 'understand', 'unfortun', 'uniqu', 'univers', 'unlik', 'use', 'usual', 'valu', 'van', 'variou', 've', 'veri', 'version', 'victim', 'video', 'view', 'viewer', 'villain', 'violenc', 'violent', 'virtual', 'visit', 'visual', 'voic', 'wa', 'wait', 'walk', 'want', 'war', 'warn', 'wasn', 'wast', 'watch', 'water', 'way', 'weak', 'wear', 'week', 'went', 'whatev', 'whi', 'white', 'wife', 'wild', 'william', 'win', 'wise', 'wish', 'wit', 'woman', 'women', 'won', 'wonder', 'word', 'work', 'world', 'wors', 'worst', 'worth', 'wouldn', 'write', 'writer', 'written', 'wrong', 'wrote', 'ye', 'year', 'york', 'young']\n"
     ]
    }
   ],
   "source": [
    "print(cnt_vector.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd800b",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a67f3aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abov</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accent</th>\n",
       "      <th>accept</th>\n",
       "      <th>achiev</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>wouldn</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078355</td>\n",
       "      <td>0.042737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048845</td>\n",
       "      <td>0.026642</td>\n",
       "      <td>0.023707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078687</td>\n",
       "      <td>0.161488</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076274</td>\n",
       "      <td>0.164619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057296</td>\n",
       "      <td>0.058530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066949</td>\n",
       "      <td>0.035194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 1017 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abil       abl  abov  absolut  accent    accept    achiev       act  \\\n",
       "118    0.0  0.000000   0.0      0.0     0.0  0.000000  0.000000  0.000000   \n",
       "1374   0.0  0.000000   0.0      0.0     0.0  0.000000  0.000000  0.078355   \n",
       "1928   0.0  0.000000   0.0      0.0     0.0  0.000000  0.000000  0.048845   \n",
       "250    0.0  0.039314   0.0      0.0     0.0  0.186440  0.000000  0.026513   \n",
       "1621   0.0  0.000000   0.0      0.0     0.0  0.000000  0.000000  0.072617   \n",
       "...    ...       ...   ...      ...     ...       ...       ...       ...   \n",
       "1459   0.0  0.046088   0.0      0.0     0.0  0.000000  0.000000  0.031082   \n",
       "1730   0.0  0.000000   0.0      0.0     0.0  0.000000  0.000000  0.057985   \n",
       "725    0.0  0.000000   0.0      0.0     0.0  0.080881  0.000000  0.000000   \n",
       "850    0.0  0.000000   0.0      0.0     0.0  0.000000  0.000000  0.040481   \n",
       "1706   0.0  0.000000   0.0      0.0     0.0  0.000000  0.076274  0.164619   \n",
       "\n",
       "        action     actor  ...    wouldn     write  writer   written     wrong  \\\n",
       "118   0.000000  0.060797  ...  0.000000  0.000000     0.0  0.000000  0.000000   \n",
       "1374  0.042737  0.000000  ...  0.000000  0.000000     0.0  0.000000  0.000000   \n",
       "1928  0.026642  0.023707  ...  0.041951  0.000000     0.0  0.000000  0.000000   \n",
       "250   0.000000  0.000000  ...  0.000000  0.000000     0.0  0.036912  0.000000   \n",
       "1621  0.000000  0.000000  ...  0.083156  0.000000     0.0  0.000000  0.000000   \n",
       "...        ...       ...  ...       ...       ...     ...       ...       ...   \n",
       "1459  0.000000  0.060341  ...  0.000000  0.000000     0.0  0.000000  0.000000   \n",
       "1730  0.000000  0.028142  ...  0.000000  0.000000     0.0  0.000000  0.000000   \n",
       "725   0.050188  0.000000  ...  0.000000  0.000000     0.0  0.000000  0.065432   \n",
       "850   0.000000  0.000000  ...  0.000000  0.000000     0.0  0.000000  0.000000   \n",
       "1706  0.000000  0.000000  ...  0.000000  0.121906     0.0  0.057296  0.058530   \n",
       "\n",
       "      wrote        ye      year      york     young  \n",
       "118     0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "1374    0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "1928    0.0  0.000000  0.020885  0.000000  0.000000  \n",
       "250     0.0  0.000000  0.022673  0.000000  0.000000  \n",
       "1621    0.0  0.000000  0.020699  0.000000  0.087115  \n",
       "...     ...       ...       ...       ...       ...  \n",
       "1459    0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "1730    0.0  0.000000  0.000000  0.000000  0.034781  \n",
       "725     0.0  0.000000  0.078687  0.161488  0.000000  \n",
       "850     0.0  0.000000  0.000000  0.000000  0.000000  \n",
       "1706    0.0  0.066949  0.035194  0.000000  0.000000  \n",
       "\n",
       "[1500 rows x 1017 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_tfidf, y, test_size=0.25, random_state=25, stratify=y)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b0c94a",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb37039",
   "metadata": {},
   "source": [
    "### 1. GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedcd0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "For good reults, data is continous and should be normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9b4a10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7eb7aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[194  71]\n",
      " [ 56 179]]\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.746\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75       265\n",
      "           1       0.72      0.76      0.74       235\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.75      0.75      0.75       500\n",
      "weighted avg       0.75      0.75      0.75       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Model Evaluation\n",
    "\n",
    "y_pred = gnb_model.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "print(\"-\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"-\"*60)\n",
    "\n",
    "clf_report = classification_report(y_pred, y_test)\n",
    "print(\"Classification Report:\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bdb192f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[661  87]\n",
      " [ 89 663]]\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.8826666666666667\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       748\n",
      "           1       0.88      0.88      0.88       752\n",
      "\n",
      "    accuracy                           0.88      1500\n",
      "   macro avg       0.88      0.88      0.88      1500\n",
      "weighted avg       0.88      0.88      0.88      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Model Evaluation\n",
    "\n",
    "y_pred_train = gnb_model.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "print(\"-\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_pred_train, y_train)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"-\"*60)\n",
    "\n",
    "clf_report = classification_report(y_pred_train, y_train)\n",
    "print(\"Classification Report:\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416329bb",
   "metadata": {},
   "source": [
    "## 2. Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca600bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Will perform well on descrete data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7702e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9dec50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[208  52]\n",
      " [ 42 198]]\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.812\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82       260\n",
      "           1       0.79      0.82      0.81       240\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.81      0.81      0.81       500\n",
      "weighted avg       0.81      0.81      0.81       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Model Evaluation\n",
    "\n",
    "y_pred = mnb_model.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "print(\"-\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"-\"*60)\n",
    "\n",
    "clf_report = classification_report(y_pred, y_test)\n",
    "print(\"Classification Report:\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0441270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[643 112]\n",
      " [107 638]]\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.854\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85       755\n",
      "           1       0.85      0.86      0.85       745\n",
      "\n",
      "    accuracy                           0.85      1500\n",
      "   macro avg       0.85      0.85      0.85      1500\n",
      "weighted avg       0.85      0.85      0.85      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Model Evaluation\n",
    "\n",
    "y_pred_train = mnb_model.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "print(\"-\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_pred_train, y_train)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"-\"*60)\n",
    "\n",
    "clf_report = classification_report(y_pred_train, y_train)\n",
    "print(\"Classification Report:\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bcc38a",
   "metadata": {},
   "source": [
    "## 3. Bernoullis NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df71b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "When we have binary descrete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2e1a07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_model = BernoulliNB()\n",
    "bnb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a07ca44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[201  72]\n",
      " [ 49 178]]\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.758\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       273\n",
      "           1       0.71      0.78      0.75       227\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.76      0.76      0.76       500\n",
      "weighted avg       0.76      0.76      0.76       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Model Evaluation\n",
    "\n",
    "y_pred = bnb_model.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "print(\"-\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"-\"*60)\n",
    "\n",
    "clf_report = classification_report(y_pred, y_test)\n",
    "print(\"Classification Report:\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "908c725e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[659 166]\n",
      " [ 91 584]]\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.8286666666666667\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84       825\n",
      "           1       0.78      0.87      0.82       675\n",
      "\n",
      "    accuracy                           0.83      1500\n",
      "   macro avg       0.83      0.83      0.83      1500\n",
      "weighted avg       0.83      0.83      0.83      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Model Evaluation\n",
    "\n",
    "y_pred_train = bnb_model.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "print(\"-\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_pred_train, y_train)\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"-\"*60)\n",
    "\n",
    "clf_report = classification_report(y_pred_train, y_train)\n",
    "print(\"Classification Report:\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c38e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51bc3293",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5323ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalized word it into base form\n",
    "- Not giving you meaningful results\n",
    "- heurastic/ dominant\n",
    "- does not take words context in consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f996b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b25fc33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hav'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = LancasterStemmer()\n",
    "lst.stem(\"having\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b6c050d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = LancasterStemmer()\n",
    "lst.stem(\"caring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01692462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = LancasterStemmer()\n",
    "lst.stem(\"Playing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "145eca0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'is',\n",
       " 'Programming',\n",
       " 'Language',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'Language',\n",
       " 'is',\n",
       " 'Preferable',\n",
       " 'for',\n",
       " 'Data',\n",
       " 'Science']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Python is Programming Language and Python Language is Preferable for Data Science\"\n",
    "\n",
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30079c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "is\n",
      "program\n",
      "langu\n",
      "and\n",
      "python\n",
      "langu\n",
      "is\n",
      "pref\n",
      "for\n",
      "dat\n",
      "sci\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "lst = LancasterStemmer()\n",
    "\n",
    "for word in tokens:\n",
    "    print(lst.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d07f47d",
   "metadata": {},
   "source": [
    "# Lemmitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4879bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "- Consider context of words\n",
    "- Giving meaningful words\n",
    "- we can add pos tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14efa045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3212c2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "lemma.lemmatize(\"having\", pos='v')  # bydefault = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05f13644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "lemma.lemmatize(\"playing\", pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6392ed85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'care'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "lemma.lemmatize(\"caring\", pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c418d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "be\n",
      "program\n",
      "language\n",
      "and\n",
      "python\n",
      "language\n",
      "be\n",
      "preferable\n",
      "for\n",
      "data\n",
      "science\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "text = \"Python is Programming Language and Python Language is Preferable for Data Science\"\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "for word in tokens:\n",
    "    print(lemma.lemmatize(word.lower(), pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ef093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
